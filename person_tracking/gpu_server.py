#!/usr/bin/env python3
"""
gpu_server.py ‚Äì laptop ‚Äúbrain‚Äù
‚Ä¢ pulls JPEG thumbnails via ZMQ 5555
‚Ä¢ runs YOLOv8 (person-only, conf 0.35)
‚Ä¢ drains queue to get latest frame only
‚Ä¢ publishes bounding-box JSON on ZMQ 5556
"""

import zmq, struct, json, cv2, numpy as np, signal, sys, pathlib, time
from ultralytics import YOLO

# --- fast JPEG decoder (TurboJPEG) -----------------------------------
try:
    from turbojpeg import TurboJPEG
    J = TurboJPEG()
    def jpeg_decode(buf: bytes) -> np.ndarray:
        return J.decode(buf)
except Exception:
    def jpeg_decode(buf: bytes) -> np.ndarray:
        return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_COLOR)
# ---------------------------------------------------------------------

MODEL_PATH = pathlib.Path("models/yolov8n.pt")
model = YOLO(str(MODEL_PATH))

ctx  = zmq.Context()
pull = ctx.socket(zmq.PULL); pull.bind("tcp://*:5555")
pub  = ctx.socket(zmq.PUB);  pub.bind("tcp://*:5556")

print("üñ•Ô∏è  YOLO server ready  (PULL 5555, PUB 5556)   Ctrl-C to quit", flush=True)
signal.signal(signal.SIGINT, lambda *_: sys.exit(0))

while True:
    buf = pull.recv()  # receive at least one frame

    # Drain the ZMQ queue to get the most recent frame only
    while True:
        try:
            buf = pull.recv(flags=zmq.DONTWAIT)
        except zmq.Again:
            break

    ts  = struct.unpack("<d", buf[:8])[0]  # first 8 bytes = timestamp
    img = jpeg_decode(buf[8:])            # decode JPEG to numpy array (BGR)

    # --- inference ---------------------------------------------------
    res   = model(img, imgsz=320, conf=0.35, classes=[0], verbose=False)[0]  # 0 = person
    boxes = res.boxes.xyxy.cpu().int().tolist()
    confs = res.boxes.conf.cpu().tolist()
    payload = [[x1, y1, x2, y2, float(c)] for (x1, y1, x2, y2), c in zip(boxes, confs)]

    # Clamp negative latencies in case of clock drift
    latency_ms = max((time.time() - ts) * 1000, 0)
    print(f"boxes {len(payload)}   latency {latency_ms:.0f} ms")

    pub.send_json({"t": ts, "boxes": payload})
#!/usr/bin/env python3
"""
gpu_server.py ‚Äì YOLO v8 + ultra-verbose diagnostics + very-light tracker
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ PULL 5555   receives   320√ó240 JPEG thumbnails from Pi
‚Ä¢ YOLOv8n     (person-only) runs on CUDA if available
‚Ä¢ A tiny centroid tracker gives each person a persistent ID
‚Ä¢ PUB  5556   sends  [x1,y1,x2,y2,id,conf] for every box
‚Ä¢ Logs per-stage latencies & end-to-end timing

2025-06-18 m  (weights-only patch + tracker-bugfix)
"""

import time, struct, signal, sys, pathlib, traceback
import cv2, numpy as np, zmq, torch
from ultralytics import YOLO

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0)  Torch ‚Äúweights-only‚Äù monkey-patch  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# PyTorch ‚â•2.6 defaults to weights_only=True which breaks Ultralytics
_orig_torch_load = torch.load
def _patched_load(*args, **kw):
    kw.setdefault('weights_only', False)
    return _orig_torch_load(*args, **kw)
torch.load = _patched_load                                       # ‚Üê boom, fixed
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# 1)   Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"[INIT ] device={device}, CUDA={torch.cuda.is_available()}")

# 2)   JPEG decode
try:
    from turbojpeg import TurboJPEG
    TJ = TurboJPEG()
    def jpeg_decode(buf):  return TJ.decode(buf)
    print("[INIT ] TurboJPEG decoder")
except Exception as e:
    print(f"[INIT ] TurboJPEG not available ({e}) ‚Üí OpenCV fallback")
    def jpeg_decode(buf):
        arr = np.frombuffer(buf, np.uint8)
        return cv2.imdecode(arr, cv2.IMREAD_COLOR)

# 3)   YOLO model
MODEL_PATH = pathlib.Path("models/yolov8n.pt")
print(f"[INIT ] Loading model: {MODEL_PATH}")
model = YOLO(str(MODEL_PATH))
model.fuse()
if device.type == 'cuda':
    model.model.to(device).eval()
    torch.backends.cudnn.benchmark = True
print("[INIT ] Model ready")

# 4)   Warm-up
dummy = np.zeros((240, 320, 3), np.uint8)
for _ in range(5):
    _ = model(dummy, imgsz=320, conf=0.35, classes=[0], verbose=False)
print("[INIT ] Warm-up complete")

# 5)   ZMQ sockets
ctx   = zmq.Context()
pull  = ctx.socket(zmq.PULL); pull.bind("tcp://*:5555"); pull.setsockopt(zmq.RCVHWM, 1)
pub   = ctx.socket(zmq.PUB ); pub .bind("tcp://*:5556")
print("üñ•Ô∏è  GPU server ready  (PULL 5555, PUB 5556) ‚Äî Ctrl-C to quit")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6)  Minimal centroid tracker ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class Track:
    _next_id = 0
    def __init__(self, cx, cy, w, h):
        self.id   = Track._next_id; Track._next_id += 1
        self.cx   = cx; self.cy = cy; self.w = w; self.h = h
        self.hits = 1   # consecutive matches
        self.miss = 0   # consecutive misses
    def update(self, cx, cy, w, h):
        self.cx, self.cy, self.w, self.h = cx, cy, w, h
        self.hits += 1; self.miss = 0
    def mark_missed(self):
        self.miss += 1

TRACK_TOLERANCE = 90          # pixels ‚Äì max centroid distance to match
MAX_MISSES      = 8           # frames before a track is dropped
tracks: list['Track'] = []    # global list

def update_tracker(dets_xyxy):
    global tracks
    # compute centroids of detections
    det_centroids = [
        ((x1+x2)//2, (y1+y2)//2, x2-x1, y2-y1, (x1,y1,x2,y2))
        for x1,y1,x2,y2 in dets_xyxy
    ]

    # assignment: greedy close-centroid
    unused_tracks = set(range(len(tracks)))
    for cx,cy,w,h,xyxy in det_centroids:
        best_t, best_d = None, TRACK_TOLERANCE+1
        for ti in unused_tracks:
            dx = tracks[ti].cx - cx; dy = tracks[ti].cy - cy
            d  = abs(dx) + abs(dy)
            if d < best_d:
                best_d, best_t = d, ti
        if best_t is not None:
            tracks[best_t].update(cx, cy, w, h)
            tracks[best_t].last_xyxy = xyxy
            unused_tracks.remove(best_t)
        else:
            t = Track(cx, cy, w, h)
            t.last_xyxy = xyxy
            tracks.append(t)

    # mark unmatched tracks
    for ti in unused_tracks:
        tracks[ti].mark_missed()

    # cull dead tracks
    tracks = [t for t in tracks if t.miss < MAX_MISSES]

    # output: [x1,y1,x2,y2,id]
    return [list(t.last_xyxy)+[t.id] for t in tracks]
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

signal.signal(signal.SIGINT, lambda *_: sys.exit(0))

# 7)   Main loop
while True:
    try:
        # ‚Äî recv
        t0  = time.time()
        msg = pull.recv()
        recv_ms = (time.time()-t0)*1000
        ts_pi  = struct.unpack('<d', msg[:8])[0]
        img    = jpeg_decode(msg[8:])
        if img is None:
            print("[DECODE] failed"); continue

        # ‚Äî inference
        ti0 = time.time()
        with torch.no_grad():
            res = model(img, imgsz=320, conf=0.35, classes=[0], verbose=False)[0]
        infer_ms = (time.time()-ti0)*1000

        dets = res.boxes.xyxy.cpu().int().tolist()
        conf = res.boxes.conf.cpu().tolist()

        # ‚Äî tracker
        trk0 = time.time()
        tracks_out = update_tracker([d[:4] for d in dets])
        track_ms   = (time.time()-trk0)*1000

        # compose payload [x1,y1,x2,y2,id,conf]  (conf matched by index)
        payload = []
        for x1,y1,x2,y2,tid in tracks_out:
            # find original detection for conf (nearest box)
            best_i, best_d = None, 1e9
            for i,(dx1,dy1,dx2,dy2) in enumerate(dets):
                d = abs(dx1-x1)+abs(dy1-y1)
                if d < best_d:
                    best_d, best_i = d, i
            payload.append([x1,y1,x2,y2,tid,float(conf[best_i] if best_i is not None else 0)])

        # ‚Äî publish
        pub.send_json({"t": ts_pi, "boxes": payload})

        # ‚Äî logs
        total_ms = recv_ms + infer_ms + track_ms
        print(f"[{len(dets):2d} det ‚Üí {len(tracks_out):2d} trk] "
              f"net={recv_ms:5.1f} ms  inf={infer_ms:5.1f} ms "
              f"trk={track_ms:5.1f} ms  total={total_ms:5.1f} ms")

    except Exception:
        print("[ERROR]", traceback.format_exc(), file=sys.stderr)